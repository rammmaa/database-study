---
title: 04 Memory Management & Buffer Pools
author: haram
layout: post
---
## 1 Introduction

* 폰 노이만(Von Neumann) 아키텍처에서, 데이터는 **연산을 수행하기 전에 메모리에 있어야 한다**. 따라서 어떤 DBMS든 많은 양의 데이터를 다루려면 디스크와 메모리 사이에서 데이터를 효율적으로 **앞뒤로 이동**시킬 수 있어야 한다. DBMS는 이를 Buffer Pool Manager로 달성할 수 있다. 
  
* 높은 수준에서, Buffer Pool Manager는 메인 메모리의 버퍼와 영속 저장소 사이에서 물리적 데이터 페이지를 옮기는 역할을 한다. 또한 캐시처럼 동작하여, 자주 쓰는 페이지는 메모리에 유지해 더 빠르게 접근하고, 사용되지 않거나 “차가운(cold)” 페이지는 저장소로 내보내(evict) 다시 공간을 확보한다.

* DBMS 관점에서는, 실제로 데이터베이스가 시스템의 가용 메모리보다 더 클 수도 있음에도 불구하고 **전체 데이터베이스가 메모리에 상주하는 것처럼 보여야** 한다. 즉 DBMS는 데이터가 어떻게 메모리에 가져와지고(fetch) 어떻게 관리되는지 신경 쓰지 않아야 한다. DBMS는 연산을 수행하기 위해 **유효한 메모리 위치 포인터**만 필요하다.

1. **Spatial Control(공간적 제어)**: 페이지가 디스크에서 물리적으로 어디에 위치하는지. 함께 자주 쓰이는 페이지들을 디스크 상에서 가능한 한 **서로 가깝게** 배치하는 것이 목표다. 이는 프리페칭(prefetching) 등 최적화에 도움이 될 수 있다.
    
2. **Temporal Control(시간적 제어)**: 페이지를 언제 메모리로 가져오고, 언제 디스크로 다시 써야 하는지. 디스크에서 데이터를 읽느라 발생하는 **stall(대기/정지)** 횟수를 최소화하는 것이 목표다.
    

---

## 2 Buffer Pool (버퍼 풀)

* 버퍼 풀은 메모리와 디스크 사이에 있는 **페이지들의 인메모리 캐시**다. 본질적으로 데이터베이스 내부에 할당된 큰 메모리 영역이며, 페이지들을 임시로 저장한다.
* 버퍼 풀은 고정 크기 프레임(frame)들의 배열로 구성된다. DBMS가 어떤 페이지를 요청하면, 버퍼 풀 매니저는 먼저 그 페이지가 이미 메모리의 프레임에 있는지 확인한다. 없으면 디스크에서 읽어(복사해) 빈 프레임에 적재한다.
* 버퍼 풀 매니저는 **write-back 캐시**로 생각한다. 즉 변경된(dirty) 페이지를 버퍼에 모아두고, 변경이 일어날 때마다 즉시 디스크에 쓰지 않는다. 반대로 **write-through 캐시**는 변경이 생길 때마다 즉시 디스크로 전파한다.
	- 튜플 저장 및 인덱스
	- 정렬 및 조인 버퍼
	- 쿼리 및 딕셔너리 캐시
	- 유지보수 및 로그 버퍼

### Buffer Pool Metadata (버퍼 풀 메타데이터)

버퍼 풀이 효율적이고 올바르게 동작하려면 특정 메타데이터를 유지해야 한다.

* 페이지 테이블(page table)은 현재 메모리에 올라와 있는 페이지들을 추적하는 인메모리 해시 테이블이다. page ID를 버퍼 풀의 프레임 위치로 매핑한다.
* 버퍼 풀에서 페이지의 순서는 디스크 상의 순서와 반드시 일치하지 않으므로, 이 추가 간접 계층(indirection layer)이 풀 안에서 페이지 위치를 식별하게 해준다. 페이지 테이블은 페이지마다 추가 메타데이터도 유지하는데, dirty flag와 pin/reference counter가 포함된다.

- **Dirty flag**: 어떤 스레드가 페이지를 수정하면 설정된다. 이는 스토리지 매니저에게, 해당 페이지는 퇴출(eviction)되기 전에 디스크에 다시 써야 함을 알려준다.
- **Pin / reference counter**: 현재 그 페이지를(읽거나 수정하며) 접근 중인 스레드 수를 추적한다. 스레드는 페이지에 접근하기 전에 카운터를 증가시켜야 한다. pin count가 0보다 크면 스토리지 매니저는 그 페이지를 메모리에서 **퇴출할 수 없다**. 다만 pinning은 다른 트랜잭션의 동시 접근을 막지는 않는다. 만약 버퍼 풀이 가득 찼는데 퇴출 가능한(핀되지 않은) 페이지가 더 이상 없으면, **out-of-memory 에러**가 발생한다.
- **Access Tracking Information**: 어떤 트랜잭션/누가 그 페이지에 접근 중인지 추적한다.

### Page Table / Page Directory 

- **페이지 디렉토리(page directory)**: page id → 물리 DB 파일 상의 페이지 위치 매핑. 재시작 시 찾을 수 있도록 모든 변경이 **디스크에 기록**되어야 한다.
- **페이지 테이블(page table)**: page id → 버퍼 풀 프레임에 올라온 “페이지 복사본” 매핑. 디스크에 저장할 필요가 없는 **인메모리 자료구조**다.

---

## 3 Operating Systems vs. Database Management Systems (OS vs DBMS)

### Locks vs. Latches (락 vs 래치)

DBMS가 내부 요소를 보호하는 방식을 논할 때, **lock**과 **latch**를 구분해야 한다.

- **Locks(락)**: 더 높은 수준의 논리적(logical) 프리미티브로, 데이터베이스의 내용(예: 튜플, 테이블, 데이터베이스)을 다른 트랜잭션으로부터 보호한다. DB 시스템은 쿼리가 실행되는 동안 어떤 락이 잡혀 있는지 사용자가 알 수 있게 노출할 수도 있다. 락은 변경을 **롤백**할 수 있어야 한다.    
- **Latches(래치)**: DBMS 내부 자료구조(예: 해시 테이블, 메모리 영역)의 크리티컬 섹션을 보호하는 저수준(low-level) 프리미티브다. 래치는 오직 해당 연산이 수행되는 **짧은 시간 동안만** 잡힌다. 래치는 롤백을 할 필요가 없다. 보통 뮤텍스(mutex)나 조건 변수(conditional variables) 같은 언어 프리미티브로 구현한다.

### Why not use the OS?

“버퍼 풀 매니저 대신 OS의 페이지 캐시를 쓰면 되지 않나?”라고 생각할 수 있다. 하지만 `mmap` 같은 메모리 매핑 파일을 쓰면 여러 문제가 있다.

1. **트랜잭션 안전성**: OS는 언제든 dirty 페이지를 flush할 수 있다.
2. **I/O 스톨**: DBMS는 어떤 페이지가 메모리에 있는지 모른다. OS가 page fault에서 스레드를 멈춰 세울 수 있다.
3. **에러 처리**: 페이지를 검증(validate)하기 어렵다. 어떤 페이지 접근이든 SIGBUS 시그널을 유발할 수 있고 DBMS가 이를 처리해야 한다.
4. **성능 문제**: OS 내부 자료구조 경합, TLB shootdown 등.
    

이 문제들 중 일부는 `madvise`, `mlock`, `msync`로 완화할 수 있지만, OS가 “제대로” 동작하도록 이런 시스템콜을 활용하는 일은 결국 **직접 메모리 관리하는 것만큼 번거롭다**.

DBMS는 거의 항상 스스로 제어하기를 원하며, OS보다 더 잘할 수 있다.

1. dirty 페이지를 **올바른 순서로** 디스크에 flush
2. 특화된 프리페칭
3. 더 나은 버퍼 교체 정책
4. 스레드/프로세스 스케줄링


---

## 4 Buffer Replacement Policies (버퍼 교체 정책)

DBMS가 새 페이지를 위한 프레임을 확보해야 할 때, 버퍼 풀에서 어떤 페이지를 퇴출할지 결정해야 하며 이를 위해 **교체 정책(replacement policy)**을 사용한다. 구현 목표는 **정확성(correctness)**, **정확도(accuracy)**, **속도(speed)**, **메타데이터 오버헤드**다.


### Least Recently Used (LRU)

* LRU는 각 페이지가 마지막으로 접근된 시간을 나타내는 타임스탬프를 유지하고, 가장 오래된 타임스탬프를 가진 페이지를 퇴출한다. 이 타임스탬프를 큐 같은 별도 자료구조에 저장해(퇴출 시 탐색 시간을 줄이기 위해) 정렬 상태를 유지할 수도 있지만, 정렬 유지와 큰 타임스탬프 저장 자체가 과도한 오버헤드가 될 수 있다.

### CLOCK

* CLOCK은 각 페이지에 별도의 타임스탬프를 두지 않고 LRU를 근사(approximation)한다. CLOCK에서는 각 페이지에 **reference bit**가 있고, 페이지가 접근되면 1로 세팅된다(일부 구현은 1보다 큰 실제 ref counter를 허용하기도 함).
* 시각화 방법: 페이지들을 원형 버퍼에 놓고 “시계 바늘(clock hand)”을 둔다. 퇴출이 필요하면 바늘을 움직이며 페이지의 비트를 확인한다. 비트가 1이면 0으로 내리고, 0이면 그 페이지를 퇴출한 뒤 그 자리에 새 페이지를 넣고 바늘을 앞으로 이동한다. 또한 CLOCK은 퇴출 사이의 바늘 위치를 기억한다.

### Issues

LRU와 CLOCK에는 여러 문제가 있다.

* LRU와 CLOCK은 모두 sequential flooding(순차 스캔 오염)에 취약하다. 순차 스캔은 많은 페이지를 빠르게 읽어 버퍼 풀이 금방 차고, 그 결과 다른 쿼리가 쓰던 페이지들이(타임스탬프가 더 오래됐기 때문에) 퇴출된다. 이런 상황(또는 분석 워크로드)에서는 **가장 최근에 사용된 페이지(MRU)**가 오히려 퇴출하기 가장 좋은 페이지인 경우가 많다.

* LRU는 접근 빈도(frequency)도 반영하지 못한다. 예를 들어 장기간에 걸쳐 자주 접근되는 페이지가 있는데 최근에만 잠깐 접근이 없었다고 해서 그 페이지를 퇴출하고 싶지는 않다. LFU(Least-Frequently Used)는 페이지마다 접근 횟수를 유지하고 횟수가 낮은 페이지를 퇴출하지만, 시간 정보를 무시해서 오래된 페이지가 누적될 수 있다.

### Alternatives

1. **LRU-K**: 최근 K번의 참조 시각을 기록하고, 연속 접근 간 간격을 계산해 다음 접근 시점을 예측한다. 하지만 저장 오버헤드가 더 크다. 또한 스래싱(thrashing)을 막고 최근 퇴출 페이지에 대한 히스토리를 남기기 위해, 최근 퇴출 페이지를 담는 인메모리 “고스트 캐시(ghost cache)”가 필요하다.
    
2. **MySQL의 LRU-2 근사**: 단일 연결 리스트(singly linked list)를 두 개의 진입점(entry point)으로 운영한다. 페이지가 접근될 때, 이미 old list에 있던 페이지면 young 큐 시작으로 옮기고, 아니면 old list의 시작에 넣는다. 퇴출은 항상 old list의 끝에서 한다.
    
3. **쿼리별 지역화(localization per query)**: DBMS가 쿼리/트랜잭션 단위로 어떤 페이지를 퇴출할지 선택한다. 각 쿼리 때문에 버퍼 풀이 오염되는(pollution) 일을 최소화한다.

또한 **priority hints**를 통해 트랜잭션이 “이 페이지가 중요한지”를 쿼리 실행 맥락에 따라 버퍼 풀에 알려줄 수 있다.

### ARC: Adaptive Replacement Cache

* ARC는 IBM Research에서 개발되었고, 워크로드 접근 패턴에 따라 두 리스트 크기를 동적으로 조정해 **LRU와 LFU**를 모두 지원한다. ARC는 최근 퇴출을 기억하기 위해 고스트 리스트를 사용한다. ARC는 **목표 크기 파라미터 p**를 이용해 “최근성(recency)”과 “빈도(frequency)”를 얼마나 선호할지 조정한다.

1. **Recency List T1**: 최근에 한 번 접근된 페이지
2. **Frequency List T2**: 최소 두 번 이상 접근된 페이지
3. **Target Size Parameter p**: 최근성(T1) vs 빈도(T2) 선호 비율을 조절
    

### Dirty Pages (더티 페이지)

* 페이지/프레임은 DBMS에 의해 수정되었음을 나타내는 **dirty flag/bit**를 가진다. dirty 페이지 퇴출 처리에는 두 경우가 있다.

	- **빠른 경로(fast path)**: 페이지가 dirty가 아니면 그냥 버려도 된다(drop).
	- **느린 경로(slow path)**: 페이지가 dirty면, 메모리와 디스크 동기화를 위해 변경 내용을 **디스크에 기록(write-back)**해야 한다.
    
* 이 비용을 줄이는 한 방법은 **백그라운드 쓰기(background writing)**다. DBMS가 주기적으로 페이지 테이블을 순회하며 dirty 페이지를 디스크에 기록한다. dirty 페이지가 안전하게 기록되면, 그 페이지를 퇴출하거나 dirty flag만 해제할 수 있다.

---

## 5 Disk I/O and OS Cache (디스크 I/O와 OS 캐시)

* OS/하드웨어는 디스크 대역폭을 최대화하려고 I/O 요청을 재정렬하고 배치한다. 하지만 어떤 I/O 요청이 더 중요한지 OS/하드웨어는 알지 못한다.

* DBMS는 시스템 전체에서 들어오는 페이지 읽기/쓰기 요청을 추적하는 내부 큐(들)를 유지한다. 작업 우선순위는 여러 요인으로 정해진다.

- 순차 I/O vs 랜덤 I/O
- 크리티컬 패스 작업 vs 백그라운드 작업
- 테이블 vs 인덱스 vs 로그 vs 임시(ephemeral) 데이터
- 트랜잭션 정보
- 사용자 기반 SLA
    

* OS는 이런 정보를 모르기 때문에 오히려 방해가 될 수 있다. 대부분의 디스크 연산은 OS API를 거치며, 특별히 지시하지 않으면 OS는 자체 파일시스템 캐시(페이지/버퍼 캐시)를 유지한다.
* 대부분의 DBMS는 **Direct I/O**(예: `O_DIRECT` 플래그)를 사용해 OS 캐시를 우회한다. 이렇게 하면 페이지의 중복 복사본이 생기는 것을 피하고, 서로 다른 퇴출 정책을 이중으로 관리할 필요도 줄어든다. 반면 PostgreSQL은 OS의 페이지 캐시를 사용하는 DBMS의 예시다.
