---
title: 04 Memory Management
author: jiyoon
layout: post
---

폰 노이만 아키텍처에서는 CPU가 디스크에 있는 데이터를 직접 처리할 수 없고, 데이터를 메모리(RAM)로 가져와야만 한다. 그렇다면 **디스크에 있는 데이터를 어떻게 효율적으로 메모리로 가져오고 관리할 수 있을까?** DBMS는 가용 메모리를 무한대처럼 쓰고 싶어 한다. 이를 위해서는 OS에게 맡기는 대신 DBMS가 직접 메모리를 관리해야 한다.

## Buffer Pool Manager

DBMS의 목표는 디스크와 메모리 사이의 데이터 이동을 관리하여 실행 엔진(Execution Engine)이 데이터가 메모리에 있는지 디스크에 있는지를 신경쓰지 않게 하는 것이다. 

#### 기본 구조 

**버퍼 풀(buffer pool)** 은 DBMS가 할당받은 거대한 메모리 공간(array)이다. 이 공간을 프레임(frame)이라는 단위로 쪼개는데, 각 프레임의 크기는 디스크의 페이지 크기와 같다. 

- **페이지 테이블(page table)**
  - 현재 어떤 페이지가 어떤 프레임에 올라와 있는지 매핑 정보를 관리
  - OS의 페이지 테이블과 별개 / DBMS 내부의 해시 테이블
- **메타데이터**
  - 각 프레임마다 유지하는 정보들
  - **Dirty Flag**: 페이지가 메모리에 올라온 뒤 수정되었는지에 대한 플래그 -> 수정되었다면 나중에 디스크에 다시 write되어야 함
  - **Pin Counter (Reference Counter)**: 현재 이 페이지를 사용 중인 스레드의 개수 -> 0이 아니면 메모리에 유지해야 함
 
#### 페이지 디렉토리 vs 페이지 테이블

- **Page Directory**: **디스크**에 저장. 페이지 ID를 파일 내 위치로 매핑
- **Page Table**: **메모리**에 저장. 페이지 ID를 버퍼 풀의 프레임으로 매핑

#### Lock vs Latches

- **Lock(락)**
  - **논리적** 보호
    - 데이터베이스 내용을 보호함
  - 트랜잭션(Transaction) 내내 유지됨
  - 사용자가 볼 수 있음
  - 롤백 가능
  - **Deadlock** 감지 및 해결 필요
- **Latches(래치)**
  - **물리적** 보호
    - 메모리 내 자료구조를 보호함
  - 이주 짧은 시간 동안만 유지됨 (critical section)
  - e.g., OS의 `std:mutex`, `spinlock`
  - Deadlock 감지 안 함 (코드로 피해주어야 함)
  - 버퍼 풀 관리자 내부에서는 Latch 사용

## Optimizations

버퍼 풀의 bottleneck을 방지하기 위한 최적화 기법들이 존재한다.

#### Multi Buffer Pools

시스템 전체에 버퍼 풀이 하나만 있으면 모든 스레드가 래치를 얻기 위해 Contention이 발생한다. -> 따라서 버퍼 풀을 여러 개 만들어 해결한다. 페이지 ID를 해싱하여 어느 버퍼 풀로 갈지 정하거나, 데이터베이스별로 나누면 래치 경쟁을 줄일 수 있다.

#### Pre-fetching

쿼리 실행 계획을 보고 데이터의 순차적 접근이 예상되는 경우, 요청하지 않은 페이지도 미리 가져온다. `SELECT * FROM table` 같은 sequential scan을 할 때 처리하는 동안 다음 페이지를 미리 디스크에서 읽어오면 I/O 대기 시간을 줄일 수 있다.

#### Scan Sharing

쿼리 A가 테이블을 쭉 읽고 있는데 쿼리 B가 같은 테이블을 읽고자 시도하면 B는 처음부터 다시 읽지 않고 A가 읽고 있는 위치(커서)에 합류한다. A와 B가 함께 끝까지 테이블을 읽고, B는 못 읽었던 앞 부분을 나중에 읽는 방식이다. 

#### Buffer Pool Bypass

한 번 읽고 다시는 안 쓸 데이터(e.g., 큰 테이블의 단순 정렬, join 등)는 버퍼 풀 공간을 낭비하는 대신 쿼리 실행 메모리에 임시로 할당했다가 바로 버린다. Light Scan이라고도 한다.
